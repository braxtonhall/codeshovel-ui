{
	"repo": "https://github.com/apache/lucene-solr.git",
	"file": "lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java",
	"method": {
		"longName": "MemoryIndex::keywordTokenStream(Collection<T> keywords)",
		"startLine": 334,
		"methodName": "keywordTokenStream",
		"isStatic": false,
		"isAbstract": false,
		"visibility": "public"
	},
	"history": {
		"e8e4245d9b36123446546ff15967ac95429ea2b0": {
			"type": "Yfilerename",
			"commitMessage": "LUCENE-3965: consolidate all api modules and fix packaging for 4.0\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1327094 13f79535-47bb-0310-9956-ffa450edef68\n",
			"commitDate": "2012-04-17, 7:36 AM",
			"commitName": "e8e4245d9b36123446546ff15967ac95429ea2b0",
			"commitAuthor": "Robert Muir",
			"commitDateOld": "2012-04-17, 6:03 AM",
			"commitNameOld": "0daa4b0aac1748bbb2c56547626e9f49e7fb4ed6",
			"commitAuthorOld": "Sami Siren",
			"daysBetweenCommits": 0.06,
			"commitsBetweenForRepo": 1,
			"commitsBetweenForFile": 1,
			"diff": "",
			"extendedDetails": {
				"oldPath": "lucene/contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java",
				"newPath": "lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java"
			}
		},
		"ad0e49591148340418569d7c650761a6d41cf1b1": {
			"type": "Ybodychange",
			"commitMessage": "LUCENE-2372: switch over remaining uses of TermAttribute\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@950008 13f79535-47bb-0310-9956-ffa450edef68\n",
			"commitDate": "2010-06-01, 4:35 AM",
			"commitName": "ad0e49591148340418569d7c650761a6d41cf1b1",
			"commitAuthor": "Robert Muir",
			"commitDateOld": "2016-01-22, 5:18 PM",
			"commitNameOld": "778d96752fa94636a2136ea2b4d58a3fcbe283ec",
			"commitAuthorOld": "Dawid Weiss",
			"daysBetweenCommits": -2061.57,
			"commitsBetweenForRepo": 0,
			"commitsBetweenForFile": 0,
			"diff": "@@ -1,28 +1,28 @@\n   public <T> TokenStream keywordTokenStream(final Collection<T> keywords) {\n     // TODO: deprecate & move this method into AnalyzerUtil?\n     if (keywords == null)\n       throw new IllegalArgumentException(\"keywords must not be null\");\n     \n     return new TokenStream() {\n       private Iterator<T> iter = keywords.iterator();\n       private int start = 0;\n-      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n-      private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n+      private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n+      private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n       \n       @Override\n       public boolean incrementToken() {\n         if (!iter.hasNext()) return false;\n         \n         T obj = iter.next();\n         if (obj == null) \n           throw new IllegalArgumentException(\"keyword must not be null\");\n         \n         String term = obj.toString();\n         clearAttributes();\n-        termAtt.setTermBuffer(term);\n-        offsetAtt.setOffset(start, start+termAtt.termLength());\n+        termAtt.setEmpty().append(term);\n+        offsetAtt.setOffset(start, start+termAtt.length());\n         start += term.length() + 1; // separate words by 1 (blank) character\n         return true;\n       }\n     };\n   }\n\\ No newline at end of file\n",
			"extendedDetails": {}
		},
		"778d96752fa94636a2136ea2b4d58a3fcbe283ec": {
			"type": "Yfilerename",
			"commitMessage": "SVN-GIT conversion, path copy emulation.\n",
			"commitDate": "2016-01-22, 5:18 PM",
			"commitName": "778d96752fa94636a2136ea2b4d58a3fcbe283ec",
			"commitAuthor": "Dawid Weiss",
			"commitDateOld": "2010-03-17, 8:57 AM",
			"commitNameOld": "2e5c6cdadc820220f8cb86e1b6e215da941649f9",
			"commitAuthorOld": "Uwe Schindler",
			"daysBetweenCommits": 2137.39,
			"commitsBetweenForRepo": 1,
			"commitsBetweenForFile": 1,
			"diff": "",
			"extendedDetails": {
				"oldPath": "contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java",
				"newPath": "lucene/contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java"
			}
		},
		"3f722b66a55ace117de6458f5b7d52f5bbc20c62": {
			"type": "Ybodychange",
			"commitMessage": "LUCENE-2211: Fix various missing clearAttributes() and improve BaseTokenStreamTestCase to check for this trap\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@899627 13f79535-47bb-0310-9956-ffa450edef68\n",
			"commitDate": "2010-01-15, 6:42 AM",
			"commitName": "3f722b66a55ace117de6458f5b7d52f5bbc20c62",
			"commitAuthor": "Uwe Schindler",
			"commitDateOld": "2009-12-05, 2:43 AM",
			"commitNameOld": "fa65d42e942dda48fcdb0a7c87c6b5f71f71bb83",
			"commitAuthorOld": "Michael McCandless",
			"daysBetweenCommits": 41.17,
			"commitsBetweenForRepo": 111,
			"commitsBetweenForFile": 1,
			"diff": "@@ -1,27 +1,28 @@\n   public <T> TokenStream keywordTokenStream(final Collection<T> keywords) {\n     // TODO: deprecate & move this method into AnalyzerUtil?\n     if (keywords == null)\n       throw new IllegalArgumentException(\"keywords must not be null\");\n     \n     return new TokenStream() {\n       private Iterator<T> iter = keywords.iterator();\n       private int start = 0;\n       private TermAttribute termAtt = addAttribute(TermAttribute.class);\n       private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n       \n       @Override\n       public boolean incrementToken() {\n         if (!iter.hasNext()) return false;\n         \n         T obj = iter.next();\n         if (obj == null) \n           throw new IllegalArgumentException(\"keyword must not be null\");\n         \n         String term = obj.toString();\n+        clearAttributes();\n         termAtt.setTermBuffer(term);\n         offsetAtt.setOffset(start, start+termAtt.termLength());\n         start += term.length() + 1; // separate words by 1 (blank) character\n         return true;\n       }\n     };\n   }\n\\ No newline at end of file\n",
			"extendedDetails": {}
		},
		"786eb6ce0d19c6459f204b5d4ab0dc72245888cb": {
			"type": "Ybodychange",
			"commitMessage": "LUCENE-2012: add remaining @overrides (contrib,demo)\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@833867 13f79535-47bb-0310-9956-ffa450edef68\n",
			"commitDate": "2009-11-08, 5:45 AM",
			"commitName": "786eb6ce0d19c6459f204b5d4ab0dc72245888cb",
			"commitAuthor": "Robert Muir",
			"commitDateOld": "2009-11-04, 3:37 PM",
			"commitNameOld": "80e8bfbbc9e4932d557d016a4f566f40459cb50d",
			"commitAuthorOld": "Robert Muir",
			"daysBetweenCommits": 3.59,
			"commitsBetweenForRepo": 16,
			"commitsBetweenForFile": 1,
			"diff": "@@ -1,26 +1,27 @@\n   public <T> TokenStream keywordTokenStream(final Collection<T> keywords) {\n     // TODO: deprecate & move this method into AnalyzerUtil?\n     if (keywords == null)\n       throw new IllegalArgumentException(\"keywords must not be null\");\n     \n     return new TokenStream() {\n       private Iterator<T> iter = keywords.iterator();\n       private int start = 0;\n       private TermAttribute termAtt = addAttribute(TermAttribute.class);\n       private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n       \n+      @Override\n       public boolean incrementToken() {\n         if (!iter.hasNext()) return false;\n         \n         T obj = iter.next();\n         if (obj == null) \n           throw new IllegalArgumentException(\"keyword must not be null\");\n         \n         String term = obj.toString();\n         termAtt.setTermBuffer(term);\n         offsetAtt.setOffset(start, start+termAtt.termLength());\n         start += term.length() + 1; // separate words by 1 (blank) character\n         return true;\n       }\n     };\n   }\n\\ No newline at end of file\n",
			"extendedDetails": {}
		},
		"786457c0e3ae6afa610788a9ffdfe6bf01c1f976": {
			"type": "Ymultichange(Yparameterchange,Ybodychange)",
			"commitMessage": "LUCENE-1257: Generics in contrib/memory, contrib/wordnet (previously memory), contrib/misc, contrib/benchmark\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@830790 13f79535-47bb-0310-9956-ffa450edef68\n",
			"commitDate": "2009-10-28, 5:21 PM",
			"commitName": "786457c0e3ae6afa610788a9ffdfe6bf01c1f976",
			"commitAuthor": "Uwe Schindler",
			"subchanges": [
				{
					"type": "Yparameterchange",
					"commitMessage": "LUCENE-1257: Generics in contrib/memory, contrib/wordnet (previously memory), contrib/misc, contrib/benchmark\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@830790 13f79535-47bb-0310-9956-ffa450edef68\n",
					"commitDate": "2009-10-28, 5:21 PM",
					"commitName": "786457c0e3ae6afa610788a9ffdfe6bf01c1f976",
					"commitAuthor": "Uwe Schindler",
					"commitDateOld": "2009-10-26, 8:55 AM",
					"commitNameOld": "74f872182ed9699d0e1d16ca98ecf72d7622cb67",
					"commitAuthorOld": "Michael McCandless",
					"daysBetweenCommits": 2.35,
					"commitsBetweenForRepo": 15,
					"commitsBetweenForFile": 1,
					"diff": "@@ -1,26 +1,26 @@\n-  public TokenStream keywordTokenStream(final Collection keywords) {\n+  public <T> TokenStream keywordTokenStream(final Collection<T> keywords) {\n     // TODO: deprecate & move this method into AnalyzerUtil?\n     if (keywords == null)\n       throw new IllegalArgumentException(\"keywords must not be null\");\n     \n     return new TokenStream() {\n-      private Iterator iter = keywords.iterator();\n+      private Iterator<T> iter = keywords.iterator();\n       private int start = 0;\n       private TermAttribute termAtt = addAttribute(TermAttribute.class);\n       private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n       \n       public boolean incrementToken() {\n         if (!iter.hasNext()) return false;\n         \n-        Object obj = iter.next();\n+        T obj = iter.next();\n         if (obj == null) \n           throw new IllegalArgumentException(\"keyword must not be null\");\n         \n         String term = obj.toString();\n         termAtt.setTermBuffer(term);\n         offsetAtt.setOffset(start, start+termAtt.termLength());\n         start += term.length() + 1; // separate words by 1 (blank) character\n         return true;\n       }\n     };\n   }\n\\ No newline at end of file\n",
					"extendedDetails": {
						"oldValue": "[keywords-Collection(modifiers-final)]",
						"newValue": "[keywords-Collection<T>(modifiers-final)]"
					}
				},
				{
					"type": "Ybodychange",
					"commitMessage": "LUCENE-1257: Generics in contrib/memory, contrib/wordnet (previously memory), contrib/misc, contrib/benchmark\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@830790 13f79535-47bb-0310-9956-ffa450edef68\n",
					"commitDate": "2009-10-28, 5:21 PM",
					"commitName": "786457c0e3ae6afa610788a9ffdfe6bf01c1f976",
					"commitAuthor": "Uwe Schindler",
					"commitDateOld": "2009-10-26, 8:55 AM",
					"commitNameOld": "74f872182ed9699d0e1d16ca98ecf72d7622cb67",
					"commitAuthorOld": "Michael McCandless",
					"daysBetweenCommits": 2.35,
					"commitsBetweenForRepo": 15,
					"commitsBetweenForFile": 1,
					"diff": "@@ -1,26 +1,26 @@\n-  public TokenStream keywordTokenStream(final Collection keywords) {\n+  public <T> TokenStream keywordTokenStream(final Collection<T> keywords) {\n     // TODO: deprecate & move this method into AnalyzerUtil?\n     if (keywords == null)\n       throw new IllegalArgumentException(\"keywords must not be null\");\n     \n     return new TokenStream() {\n-      private Iterator iter = keywords.iterator();\n+      private Iterator<T> iter = keywords.iterator();\n       private int start = 0;\n       private TermAttribute termAtt = addAttribute(TermAttribute.class);\n       private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n       \n       public boolean incrementToken() {\n         if (!iter.hasNext()) return false;\n         \n-        Object obj = iter.next();\n+        T obj = iter.next();\n         if (obj == null) \n           throw new IllegalArgumentException(\"keyword must not be null\");\n         \n         String term = obj.toString();\n         termAtt.setTermBuffer(term);\n         offsetAtt.setOffset(start, start+termAtt.termLength());\n         start += term.length() + 1; // separate words by 1 (blank) character\n         return true;\n       }\n     };\n   }\n\\ No newline at end of file\n",
					"extendedDetails": {}
				}
			]
		},
		"ec90bc2202ef501e257eaf235be5ca15239c03c2": {
			"type": "Ybodychange",
			"commitMessage": "LUCENE-1855: Change AttributeSource API to use generics\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@820553 13f79535-47bb-0310-9956-ffa450edef68\n",
			"commitDate": "2009-10-01, 1:53 AM",
			"commitName": "ec90bc2202ef501e257eaf235be5ca15239c03c2",
			"commitAuthor": "Uwe Schindler",
			"commitDateOld": "2009-08-26, 5:14 PM",
			"commitNameOld": "f39dadfb26311d99b266affd8eb62456f4fbeb9f",
			"commitAuthorOld": "Mark Robert Miller",
			"daysBetweenCommits": 35.36,
			"commitsBetweenForRepo": 105,
			"commitsBetweenForFile": 1,
			"diff": "@@ -1,26 +1,26 @@\n   public TokenStream keywordTokenStream(final Collection keywords) {\n     // TODO: deprecate & move this method into AnalyzerUtil?\n     if (keywords == null)\n       throw new IllegalArgumentException(\"keywords must not be null\");\n     \n     return new TokenStream() {\n       private Iterator iter = keywords.iterator();\n       private int start = 0;\n-      private TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);\n-      private OffsetAttribute offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);\n+      private TermAttribute termAtt = addAttribute(TermAttribute.class);\n+      private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n       \n       public boolean incrementToken() {\n         if (!iter.hasNext()) return false;\n         \n         Object obj = iter.next();\n         if (obj == null) \n           throw new IllegalArgumentException(\"keyword must not be null\");\n         \n         String term = obj.toString();\n         termAtt.setTermBuffer(term);\n         offsetAtt.setOffset(start, start+termAtt.termLength());\n         start += term.length() + 1; // separate words by 1 (blank) character\n         return true;\n       }\n     };\n   }\n\\ No newline at end of file\n",
			"extendedDetails": {}
		},
		"1743081b078a3206e676bdd4ebe9203f5bad6c90": {
			"type": "Ybodychange",
			"commitMessage": "LUCENE-1460: Changed TokenStreams/TokenFilters in contrib to use the new TokenStream API.\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@799953 13f79535-47bb-0310-9956-ffa450edef68\n",
			"commitDate": "2009-08-01, 4:52 PM",
			"commitName": "1743081b078a3206e676bdd4ebe9203f5bad6c90",
			"commitAuthor": "Michael Busch",
			"commitDateOld": "2009-01-25, 7:38 AM",
			"commitNameOld": "c6f6f016433ffe8450e4b2f202c9ac5b848305ec",
			"commitAuthorOld": "Michael McCandless",
			"daysBetweenCommits": 188.34,
			"commitsBetweenForRepo": 413,
			"commitsBetweenForFile": 1,
			"diff": "@@ -1,23 +1,26 @@\n   public TokenStream keywordTokenStream(final Collection keywords) {\n     // TODO: deprecate & move this method into AnalyzerUtil?\n     if (keywords == null)\n       throw new IllegalArgumentException(\"keywords must not be null\");\n     \n     return new TokenStream() {\n       private Iterator iter = keywords.iterator();\n       private int start = 0;\n-      public Token next(final Token reusableToken) {\n-        assert reusableToken != null;\n-        if (!iter.hasNext()) return null;\n+      private TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);\n+      private OffsetAttribute offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);\n+      \n+      public boolean incrementToken() {\n+        if (!iter.hasNext()) return false;\n         \n         Object obj = iter.next();\n         if (obj == null) \n           throw new IllegalArgumentException(\"keyword must not be null\");\n         \n         String term = obj.toString();\n-        reusableToken.reinit(term, start, start+reusableToken.termLength());\n+        termAtt.setTermBuffer(term);\n+        offsetAtt.setOffset(start, start+termAtt.termLength());\n         start += term.length() + 1; // separate words by 1 (blank) character\n-        return reusableToken;\n+        return true;\n       }\n     };\n   }\n\\ No newline at end of file\n",
			"extendedDetails": {}
		},
		"bb6b7117186b656b4777850fdc463e0eaa541130": {
			"type": "Ybodychange",
			"commitMessage": "LUCENE-1333: improvements to Token reuse API and full cutover to reuse API for all core and contrib analyzers\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@687357 13f79535-47bb-0310-9956-ffa450edef68\n",
			"commitDate": "2008-08-20, 8:38 AM",
			"commitName": "bb6b7117186b656b4777850fdc463e0eaa541130",
			"commitAuthor": "Michael McCandless",
			"commitDateOld": "2008-08-19, 4:40 AM",
			"commitNameOld": "e31a9da835c6e381bbcd46aa4390089f6bcc1c15",
			"commitAuthorOld": "Michael McCandless",
			"daysBetweenCommits": 1.16,
			"commitsBetweenForRepo": 4,
			"commitsBetweenForFile": 1,
			"diff": "@@ -1,22 +1,23 @@\n   public TokenStream keywordTokenStream(final Collection keywords) {\n     // TODO: deprecate & move this method into AnalyzerUtil?\n     if (keywords == null)\n       throw new IllegalArgumentException(\"keywords must not be null\");\n     \n     return new TokenStream() {\n       private Iterator iter = keywords.iterator();\n       private int start = 0;\n-      public Token next() {\n+      public Token next(final Token reusableToken) {\n+        assert reusableToken != null;\n         if (!iter.hasNext()) return null;\n         \n         Object obj = iter.next();\n         if (obj == null) \n           throw new IllegalArgumentException(\"keyword must not be null\");\n         \n         String term = obj.toString();\n-        Token token = new Token(term, start, start + term.length());\n+        reusableToken.reinit(term, start, start+reusableToken.termLength());\n         start += term.length() + 1; // separate words by 1 (blank) character\n-        return token;\n+        return reusableToken;\n       }\n     };\n   }\n\\ No newline at end of file\n",
			"extendedDetails": {}
		},
		"e28541354d496a43078c1bc281076f97ed7d008c": {
			"type": "Yintroduced",
			"commitMessage": "some performance improvements\n\ngit-svn-id: https://svn.apache.org/repos/asf/lucene/java/trunk@351891 13f79535-47bb-0310-9956-ffa450edef68\n",
			"commitDate": "2005-12-02, 10:24 PM",
			"commitName": "e28541354d496a43078c1bc281076f97ed7d008c",
			"commitAuthor": "Wolfgang Hoschek"
		}
	},
	"sha": "38bf976cd4b9e324c21664bd7ae3d554df803705"
}